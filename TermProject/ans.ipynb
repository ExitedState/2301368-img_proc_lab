{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def segment_logo(image_path, background_color=(255, 255, 255)):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(blurred, 100, 200)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assuming largest contour is the logo (This might not always be the case)\n",
    "    # Sort contours by area and get the largest\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:1]\n",
    "\n",
    "    # Create an empty mask\n",
    "    mask = np.zeros_like(gray)\n",
    "\n",
    "    # Draw the contour on the mask\n",
    "    cv2.drawContours(mask, contours, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Create a solid color image for background\n",
    "    background = np.full_like(img, background_color, dtype=np.uint8)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    result = np.where(mask[..., None].astype(bool), img, background)\n",
    "\n",
    "    return result\n",
    "\n",
    "# This is a placeholder since we need an actual image path.\n",
    "# Replace 'path_to_handbag_image.jpg' with the actual image path.\n",
    "segmented_logo = segment_logo('./handbag1.jpg')\n",
    "\n",
    "# Displaying the result (this will not work in this text-only environment)\n",
    "# but in a Python environment, you can use:\n",
    "plt.imshow(cv2.cvtColor(segmented_logo, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Re-read the original image\n",
    "img = cv2.imread(\"./handbag2.jpeg\")\n",
    "\n",
    "# Convert to grayscale for processing\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Enhance contrast using histogram equalization\n",
    "equalized = cv2.equalizeHist(gray)\n",
    "\n",
    "# Edge detection using Canny\n",
    "edges = cv2.Canny(equalized, 100, 200)\n",
    "\n",
    "# Dilate the edges to make the contours of the logo more pronounced\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "dilation = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Assuming the logo is one of the prominent contours\n",
    "# Instead of assuming largest, we can look for a contour with a distinct area or shape\n",
    "# This threshold can be tuned, and this part of the code might need to be adjusted\n",
    "# based on the specific characteristics of the logo we're trying to segment\n",
    "contour_areas = [(i, cv2.contourArea(c)) for i, c in enumerate(contours)]\n",
    "contour_areas = sorted(contour_areas, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# This is a heuristic approach; we assume the logo is not too small or the largest\n",
    "# Let's assume the logo is within the top 3 largest contours but not the largest\n",
    "# (as the largest might be the whole bag or a part that is not of interest)\n",
    "potential_logo_indices = [idx for idx, area in contour_areas[1:3]]\n",
    "\n",
    "# Create an empty mask\n",
    "mask = np.zeros_like(gray)\n",
    "\n",
    "# Draw the potential logo contours on the mask\n",
    "for i in potential_logo_indices:\n",
    "    cv2.drawContours(mask, contours, i, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# Invert the mask so the logo area is black and the rest is white\n",
    "inverse_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Create a solid color background image\n",
    "background_color = (255, 255, 255)\n",
    "background = np.full_like(img, background_color, dtype=np.uint8)\n",
    "\n",
    "# Apply the inverse mask to the background (to color only non-logo areas)\n",
    "colored_background = cv2.bitwise_and(background, background, mask=inverse_mask)\n",
    "\n",
    "# Apply the original mask to the image (to keep only the logo area)\n",
    "logo = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "# Combine the original logo and the new background\n",
    "segmented_image_with_logo = cv2.add(logo, colored_background)\n",
    "\n",
    "# Display the image (for visualization in this notebook)\n",
    "plt.imshow(cv2.cvtColor(segmented_image_with_logo, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color, filters, morphology, measure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For the sake of example, let's assume we have a sample image loaded\n",
    "# Since we cannot load external images directly, replace 'sample_image.jpg' with the actual image file path\n",
    "image_path = './handbag8.jpeg'  # Placeholder for user-provided image path\n",
    "\n",
    "# Load the image using scikit-image\n",
    "image = io.imread(image_path)\n",
    "gray_image = color.rgb2gray(image)\n",
    "\n",
    "# Enhance edges using the Sobel filter\n",
    "edges = filters.sobel(gray_image)\n",
    "\n",
    "# Apply a threshold to get a binary image\n",
    "threshold_value = filters.threshold_otsu(edges)\n",
    "binary_mask = edges > threshold_value\n",
    "\n",
    "# Perform morphological operations to remove small objects and clean up the mask\n",
    "cleaned_mask = morphology.remove_small_objects(binary_mask, min_size=500)  # min_size can be adjusted\n",
    "cleaned_mask = morphology.remove_small_holes(cleaned_mask, area_threshold=500)  # area_threshold can be adjusted\n",
    "\n",
    "# Label the image\n",
    "labeled_image = measure.label(cleaned_mask)\n",
    "\n",
    "# Assume the largest object is the logo (this may need to be adjusted)\n",
    "regions = measure.regionprops(labeled_image)\n",
    "largest_region = max(regions, key=lambda r: r.area)\n",
    "\n",
    "# Create a mask for the largest object\n",
    "logo_mask = np.zeros_like(gray_image, dtype=bool)\n",
    "for coord in largest_region.coords:\n",
    "    logo_mask[coord[0], coord[1]] = True\n",
    "\n",
    "# Apply the mask to the original image to extract the logo\n",
    "logo = image.copy()\n",
    "for i in range(3):  # Assuming image has 3 color channels\n",
    "    logo[:, :, i] = logo[:, :, i] * logo_mask\n",
    "\n",
    "# Display the original image and the extracted logo side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Extracted logo\n",
    "ax[1].imshow(logo)\n",
    "ax[1].set_title('Extracted Logo')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "# Load your image\n",
    "image = io.imread('./handbag1.jpg')  # Replace with the path to your image\n",
    "\n",
    "# If the image is not in grayscale, convert it\n",
    "gray_image = color.rgb2gray(image) if len(image.shape) == 3 else image\n",
    "\n",
    "# Rest of your code\n",
    "thresh = threshold_otsu(gray_image)\n",
    "print(thresh)\n",
    "bw = closing(gray_image > thresh, square(3))\n",
    "\n",
    "# remove artifacts connected to image border\n",
    "cleared = clear_border(bw)\n",
    "\n",
    "# label image regions\n",
    "label_image = label(cleared)\n",
    "image_label_overlay = label2rgb(label_image, image=image, bg_label=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(image_label_overlay)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_logo_skimage(image):\n",
    "    # Apply Otsu's thresholding\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    thresh = threshold_otsu(gray_image)\n",
    "    bw = closing(gray_image > thresh, square(2))\n",
    "\n",
    "    # Remove artifacts connected to image border\n",
    "    cleared = clear_border(bw)\n",
    "\n",
    "    # Label image regions\n",
    "    label_image = label(cleared)\n",
    "\n",
    "    # Create an overlay image with transparent background\n",
    "    image_label_overlay = label2rgb(label_image, image=image, bg_label=0)\n",
    "\n",
    "    # Find the logo region\n",
    "    regions = regionprops(label_image)\n",
    "    logo_region = max(regions, key=lambda r: r.area)  # Assuming the logo is the largest region\n",
    "\n",
    "    # Create a mask for the logo\n",
    "    logo_mask = np.zeros_like(gray_image)\n",
    "    minr, minc, maxr, maxc = logo_region.bbox\n",
    "    logo_mask[minr:maxr, minc:maxc] = label_image[minr:maxr, minc:maxc] == logo_region.label\n",
    "\n",
    "    # Extract the logo from the original image\n",
    "    logo = np.zeros_like(image)\n",
    "    for i in range(3):  # for each color channel\n",
    "        logo[:, :, i] = image[:, :, i] * logo_mask\n",
    "\n",
    "    # Change background to a solid color (e.g., white)\n",
    "    background_color = [255, 255, 255]  # White background\n",
    "    for i in range(3):  # for each color channel\n",
    "        logo[:, :, i][logo_mask == 0] = background_color[i]\n",
    "\n",
    "    return logo\n",
    "\n",
    "image = cv2.imread('./handbag8.jpeg')\n",
    "logo = segment_logo_skimage(image)\n",
    "# Display the original image and the extracted logo side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Extracted logo\n",
    "ax[1].imshow(logo)\n",
    "ax[1].set_title('Extracted Logo')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def segment_logo(image):\n",
    "  \"\"\"Segments the logo on a handbag.\n",
    "\n",
    "  Args:\n",
    "    image: A color image of a handbag.\n",
    "\n",
    "  Returns:\n",
    "    An image that contains only the logo on a solid color background.\n",
    "  \"\"\"\n",
    "\n",
    "  # Convert the image to HSV color space.\n",
    "  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "  # Define the lower and upper bounds of the logo color.\n",
    "  # This will need to be adjusted based on the actual color of the logo.\n",
    "  lower_bound = np.array([0, 0, 100])\n",
    "  upper_bound = np.array([10, 255, 255])\n",
    "\n",
    "  # Create a mask based on the color threshold.\n",
    "  mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "  # Apply the mask to the image to segment the logo.\n",
    "  logo = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "  # Change the background of the image to solid color.\n",
    "  background = np.ones(image.shape, dtype=np.uint8) * 255\n",
    "  logo = cv2.bitwise_or(logo, background, mask=np.bitwise_not(mask))\n",
    "\n",
    "  return logo\n",
    "\n",
    "\n",
    "# Load the input image.\n",
    "image = cv2.imread(\"handbag1.jpg\")\n",
    "\n",
    "# Segment the logo on the handbag.\n",
    "logo = segment_logo(image)\n",
    "\n",
    "# Save the output image.\n",
    "cv2.imwrite(\"logo.jpg\", logo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load VIA JSON annotations\n",
    "with open('./via_project_14Dec2023_11h31m.json') as json_file:\n",
    "    annotations = json.load(json_file)\n",
    "\n",
    "def create_mask_from_via(via_annotation, image_shape):\n",
    "    mask = np.zeros(image_shape[:2], dtype=np.uint8)\n",
    "    for region in via_annotation['regions']:\n",
    "        shape_attributes = region['shape_attributes']\n",
    "        if shape_attributes['name'] == 'circle':\n",
    "            cv2.circle(mask, (shape_attributes['cx'], shape_attributes['cy']),\n",
    "                       shape_attributes['r'], 255, -1)\n",
    "        elif shape_attributes['name'] == 'polyline' or shape_attributes['name'] == 'polygon':\n",
    "            pts = np.array(list(zip(shape_attributes['all_points_x'], shape_attributes['all_points_y'])), np.int32)\n",
    "            cv2.fillPoly(mask, [pts], 255)\n",
    "        elif shape_attributes['name'] == 'rect':\n",
    "            cv2.rectangle(mask, (shape_attributes['x'], shape_attributes['y']),\n",
    "                          (shape_attributes['x'] + shape_attributes['width'],\n",
    "                           shape_attributes['y'] + shape_attributes['height']), 255, -1)\n",
    "        # Add other shapes if necessary\n",
    "    return mask\n",
    "\n",
    "# Directory where the images are stored\n",
    "image_dir = './temp/clean/'\n",
    "\n",
    "for image_id, via_annotation in annotations['_via_img_metadata'].items():\n",
    "    image_filename = via_annotation['filename']\n",
    "    image_path = os.path.join(image_dir, image_filename)\n",
    "\n",
    "    # Load image to get the shape\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = create_mask_from_via(via_annotation, image.shape)\n",
    "\n",
    "    # Save mask to file or use it directly for training your model\n",
    "    mask_filename = os.path.splitext(image_filename)[0] + '.png'\n",
    "    mask_path = os.path.join('./temp/masks/', mask_filename)\n",
    "    cv2.imwrite(mask_path, mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define data directories and paths\n",
    "train_data_dir = \"./train/images/\"\n",
    "train_mask_dir = \"./train/masks/\"\n",
    "val_data_dir = \"./validation/images/\"\n",
    "val_mask_dir = \"./validation/masks/\"\n",
    "\n",
    "# Define image dimensions and number of channels\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "num_channels = 3\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Generate data batches for training and validation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    mask_dir=train_mask_dir\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=16,\n",
    "    class_mode=\"binary\",\n",
    "    mask_dir=val_mask_dir\n",
    ")\n",
    "\n",
    "# Define U-Net model\n",
    "inputs = Input(shape=(img_height, img_width, num_channels))\n",
    "\n",
    "# Encoder path\n",
    "down1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "down1 = Conv2D(64, (3, 3), activation='relu', padding='same')(down1)\n",
    "pool1 = MaxPooling2D((2, 2))(down1)\n",
    "\n",
    "down2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "down2 = Conv2D(128, (3, 3), activation='relu', padding='same')(down2)\n",
    "pool2 = MaxPooling2D((2, 2))(down2)\n",
    "\n",
    "down3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "down3 = Conv2D(256, (3, 3), activation='relu', padding='same')(down3)\n",
    "pool3 = MaxPooling2D((2, 2))(down3)\n",
    "\n",
    "down4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "down4 = Conv2D(512, (3, 3), activation='relu', padding='same')(down4)\n",
    "\n",
    "# Decoder path\n",
    "up1 = UpSampling2D((2, 2))(down4)\n",
    "up1 = Concatenate()([up1, down3])\n",
    "up1 = Conv2D(256, (3, 3), activation='relu', padding='same')(up1)\n",
    "up1 = Conv2D(256, (3, 3), activation='relu', padding='same')(up1)\n",
    "\n",
    "up2 = UpSampling2D((2, 2))(up1)\n",
    "up2 = Concatenate()([up2, down2])\n",
    "up2 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n",
    "up2 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n",
    "\n",
    "up3 = UpSampling2D((2, 2))(up2)\n",
    "up3 = Concatenate()([up3, down1])\n",
    "up3 = Conv2D(64, (3, 3), activation='relu', padding='same')(up3)\n",
    "up3 = Conv2D(64, (3, 3), activation='relu', padding='same')(up3)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(up3)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"trained_unet_model.h5\")\n",
    "\n",
    "# Load and use the trained model for logo segmentation on new images\n",
    "def segment_logo(image):\n",
    "    # Preprocess the image\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (img_height, img_width))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Predict the mask\n",
    "    mask = model.predict(image)[0]\n",
    "\n",
    "    # Threshold and post-process the mask\n",
    "    mask = (mask > 0.5).astype(np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel=np.ones((3, 3), np.uint8))\n",
    "\n",
    "    # Segment the logo and combine with background\n",
    "    logo = image[0] * mask\n",
    "    background = np.ones_like(logo) * 255\n",
    "    segmented_logo = cv2.bitwise_or(logo, background)\n",
    "\n",
    "    return segmented_logo\n",
    "\n",
    "# Example usage\n",
    "segmented_logo = segment_logo(\"./test/handbag1.jpg\")\n",
    "cv2.imwrite(\"segmented_logo.jpg\", segmented_logo)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
